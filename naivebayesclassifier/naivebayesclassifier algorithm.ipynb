{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4d1cb47",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.005932,
     "end_time": "2024-03-26T05:55:38.957554",
     "exception": false,
     "start_time": "2024-03-26T05:55:38.951622",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Created by yunsuxiaozi 2024/3/26\n",
    "\n",
    "### 在这个notebook中,我们将介绍朴素贝叶斯算法的数学原理和代码实现,并使用Kaggle上的数据集来测试算法的效果,最后和开源库的效果进行比较.\n",
    "\n",
    "## 数学原理:\n",
    "\n",
    "### 首先是$P(A|B)P(B)=P(B|A)P(A)$,直接看公式可能不舒服,我解释一下.$P(B)$是B事件发生的概率,$P(A|B)$是B事件发生的情况下A事件发生的概率.所以$P(A|B)P(B)$是A,B事件同时发生的概率.后半部分也是A,B事件同时发生的概率,故相等.\n",
    "\n",
    "### 我们可以将这个公式变成:$P(A|B)=\\frac{P(B|A)P(A)}{P(B)}$.\n",
    "\n",
    "### 我们一般用朴素贝叶斯是做分类任务的,比如我们想知道当$X=X0$时,$y=y0$的概率是多大,用公式表示就是$P(y=y0|X=X0)=\\frac{P(X=X0|y=y0)P(y=y0)}{P(X=X0)}$\n",
    "\n",
    "### 这里我们$X$的每个特征(每列)都是类别型变量,同时朴素贝叶斯是假设每个特征都是独立的,即:$P(X0[0],X0[1],……,X0[n]|y0)=P(X0[0]|y=y0)P(X0[1]|y0)……P(X0[n]|y=y0)$\n",
    "\n",
    "### 所以,$P(y=y0|X=X0)=\\frac{P(X0[0]|y=y0)P(X0[1]|y=y0)……P(X0[n]|y=y0)P(y=y0)}{P(X=X0)}$.这就是朴素贝叶斯分类器的原理.\n",
    "\n",
    "### 接下来来仔细研究一下公式每部分:\n",
    "\n",
    "- 分母是P(X=X0).这个其实是个定值,因为当训练数据确定,比如总共有2个特征,第1个特征2个类别,第2个特征3个类别,那么X的取值就有6种,X0无论是其中任意一种,$P(X=X0)=\\frac{1}{6}$.由于这个值是定值,所以在算法实现上可以去掉.\n",
    "\n",
    "- 分子中P(y=y0):这个其实就是y取某个类别的概率,这个取决于训练数据target的数据分布.\n",
    "\n",
    "- 分子中P(X0[0]|y=y0)P(X0[1]|y=y0)……P(X0[n]|y=y0):其实就是在y=y0时那些数据中X的第i个特征取到X0[i]的概率.\n",
    "\n",
    "### 在算法的实现上,P(X=X0)这部分可以去掉,还需要考虑到预测概率的归一化.最后实现算法的时候是P(y=y0|X=X0):= P(X0[0]|y=y0)P(X0[1]|y=y0)……P(X0[n]|y=y0)P(y=y0),由于是一堆概率相乘,而概率值又是0到1之间的数,所以之后的概率肯定会非常小,我们在做多分类任务的时候要考虑将概率值进行归一化,使它最终的预测概率求和等于1.这里用P/sum(P)来进行归一化.\n",
    "\n",
    "### 下面我们通过Kaggle上<a href=\"https://www.kaggle.com/competitions/nlp-getting-started\">入门自然语言处理的比赛数据</a>来实现算法,并和python现有库进行比较."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd1ff92",
   "metadata": {
    "papermill": {
     "duration": 0.005128,
     "end_time": "2024-03-26T05:55:38.968366",
     "exception": false,
     "start_time": "2024-03-26T05:55:38.963238",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 导入必要的python库,并固定随机种子,保证模型可以复现."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0244f1c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T05:55:38.982068Z",
     "iopub.status.busy": "2024-03-26T05:55:38.981028Z",
     "iopub.status.idle": "2024-03-26T05:55:40.059558Z",
     "shell.execute_reply": "2024-03-26T05:55:40.058299Z"
    },
    "papermill": {
     "duration": 1.088981,
     "end_time": "2024-03-26T05:55:40.062687",
     "exception": false,
     "start_time": "2024-03-26T05:55:38.973706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd#导入csv文件的库\n",
    "import numpy as np#进行矩阵运算的库\n",
    "import re#用于正则表达式提取\n",
    "import warnings#避免一些可以忽略的报错\n",
    "warnings.filterwarnings('ignore')#filterwarnings()方法是用于设置警告过滤器的方法，它可以控制警告信息的输出方式和级别。\n",
    "\n",
    "import random#提供了一些用于生成随机数的函数\n",
    "class Config():\n",
    "    seed=2024\n",
    "    word_count=1000#统计出现最多的几个词\n",
    "    train_path=\"/kaggle/input/nlp-getting-started/train.csv\"\n",
    "    test_path=\"/kaggle/input/nlp-getting-started/test.csv\"\n",
    "#设置随机种子,保证模型可以复现\n",
    "def seed_everything(seed):\n",
    "    np.random.seed(seed)#numpy的随机种子\n",
    "    random.seed(seed)#python内置的随机种子\n",
    "seed_everything(seed=Config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28eb857d",
   "metadata": {
    "papermill": {
     "duration": 0.005166,
     "end_time": "2024-03-26T05:55:40.073628",
     "exception": false,
     "start_time": "2024-03-26T05:55:40.068462",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 这里是导入训练数据,并对数据进行了一些清洗."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "715bb4a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T05:55:40.087545Z",
     "iopub.status.busy": "2024-03-26T05:55:40.086515Z",
     "iopub.status.idle": "2024-03-26T05:55:50.271395Z",
     "shell.execute_reply": "2024-03-26T05:55:50.267910Z"
    },
    "papermill": {
     "duration": 10.195548,
     "end_time": "2024-03-26T05:55:50.274620",
     "exception": false,
     "start_time": "2024-03-26T05:55:40.079072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 8.82 µs\n",
      "len(train_df):7613\n",
      "len(test_df):3263\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[happenedterrible, car, crash]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[heard, earthquake, different, cities, stay, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[isforest, fire, spot, pond, geese, fleeing, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[apocalypse, lighting, spokane, wildfires]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[typhoon, soudelor, kills, china, taiwan]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                     [happenedterrible, car, crash]\n",
       "1   2     NaN      NaN  [heard, earthquake, different, cities, stay, s...\n",
       "2   3     NaN      NaN  [isforest, fire, spot, pond, geese, fleeing, a...\n",
       "3   9     NaN      NaN         [apocalypse, lighting, spokane, wildfires]\n",
       "4  11     NaN      NaN          [typhoon, soudelor, kills, china, taiwan]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "import nltk#Natural Language Tokens 强大的自然语言处理库\n",
    "from nltk.corpus import stopwords#导入英语的停用词表\n",
    "import re#正则表达式操作的库\n",
    "import emoji#处理字符串中的表情符号\n",
    "#去除html标签的函数\n",
    "def removeHTML(x):\n",
    "    #用正则表达式提取例如<p>,<div>之类的标签\n",
    "    html=re.compile(r'<.*?>')\n",
    "    #用空字符串去替代这些标签.\n",
    "    return html.sub(r'',x)\n",
    "#对文本数据进行数据预处理,去除对于情感分析没有用的词.\n",
    "def dataPreprocessing(x):  \n",
    "    #导入英文的停用词\n",
    "    stopword = stopwords.words('english')#导入英文的停用词\n",
    "    #将字符串转成小写字母\n",
    "    x = x.lower()\n",
    "    #将字符串去除html标签\n",
    "    x = removeHTML(x)\n",
    "    #将文本中的表情符号（emoji）转换为文本文本形式。例如，将表示笑脸的\" \"表情符号转换为\":face_with_tears_of_joy:\"。delimiters=(\" \", \" \")是分隔符.\n",
    "    x = emoji.demojize(x, delimiters=(\" \", \" \"))\n",
    "    #将评论中“@匀速小子”之类的字母、数字或下划线(\\w)替换成空格.\n",
    "    x = re.sub(\"@\\w+\", '',x)\n",
    "    #删除评论中带单引号的数字\n",
    "    x = re.sub(\"'\\d+\", '',x)\n",
    "    #删除评论中所有的数字\n",
    "    x = re.sub(\"\\d+\", '',x)\n",
    "    #删除评论中的标点符号和特征字符,将不是(^)字母、数字或下划线(\\w)或者空格(\\s)的字符替换成空格.\n",
    "    x = re.sub(r\"[^\\w\\s]\", '',x)\n",
    "    #删除url:http格式的\n",
    "    x = re.sub(\"http\\w+\", '',x)\n",
    "    #将单个的小写字母替换成空格\n",
    "    x = re.sub(\"\\s[a-z]\\s\", '',x)\n",
    "    #删除字符串开头和结尾的空格字符\n",
    "    x = x.strip()\n",
    "    #将文本分割成单词或者标点符号（tokenization）\n",
    "    tokens=nltk.word_tokenize(x)\n",
    "    tokens=[token for token in tokens if token not in stopword] \n",
    "    #返回处理好的字符串\n",
    "    return tokens\n",
    "train_df=pd.read_csv(Config.train_path)\n",
    "train_df['text']=train_df['text'].apply(dataPreprocessing)\n",
    "print(f\"len(train_df):{len(train_df)}\")\n",
    "\n",
    "test_df=pd.read_csv(Config.test_path)\n",
    "test_df['text']=test_df['text'].apply(dataPreprocessing)\n",
    "print(f\"len(test_df):{len(test_df)}\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf83442",
   "metadata": {
    "papermill": {
     "duration": 0.005942,
     "end_time": "2024-03-26T05:55:50.287338",
     "exception": false,
     "start_time": "2024-03-26T05:55:50.281396",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 这里将训练数据的文本统计成字典,并选择出现次数最多的1000个词."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1ac0aac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T05:55:50.301747Z",
     "iopub.status.busy": "2024-03-26T05:55:50.301291Z",
     "iopub.status.idle": "2024-03-26T05:55:50.383600Z",
     "shell.execute_reply": "2024-03-26T05:55:50.382379Z"
    },
    "papermill": {
     "duration": 0.092925,
     "end_time": "2024-03-26T05:55:50.386441",
     "exception": false,
     "start_time": "2024-03-26T05:55:50.293516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amp', 'im', 'like', 'fire', 'via', 'new', 'news', 'get', 'one', 'people']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=train_df['text'].values\n",
    "word_dict={}\n",
    "for i in range(len(text)):\n",
    "    for j in range(len(text[i])):\n",
    "        if text[i][j] in word_dict:\n",
    "            word_dict[text[i][j]]+=1\n",
    "        else:\n",
    "            word_dict[text[i][j]]=1\n",
    "#word_dict.items() 是key和value,sorted是排序,按照-value按照从小到大排序\n",
    "sorted_items = sorted(word_dict.items(), key=lambda x: -x[1])\n",
    "\n",
    "sorted_list = list(sorted_items)\n",
    "top_words=[value[0] for value in sorted_list[:Config.word_count]]\n",
    "top_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6e4a1c",
   "metadata": {
    "papermill": {
     "duration": 0.006087,
     "end_time": "2024-03-26T05:55:50.399011",
     "exception": false,
     "start_time": "2024-03-26T05:55:50.392924",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 构造训练数据和测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d4a30a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T05:55:50.414659Z",
     "iopub.status.busy": "2024-03-26T05:55:50.414263Z",
     "iopub.status.idle": "2024-03-26T05:55:54.484832Z",
     "shell.execute_reply": "2024-03-26T05:55:54.483286Z"
    },
    "papermill": {
     "duration": 4.081873,
     "end_time": "2024-03-26T05:55:54.487701",
     "exception": false,
     "start_time": "2024-03-26T05:55:50.405828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape:(7613, 1000),y.shape:(7613,)\n"
     ]
    }
   ],
   "source": [
    "train_text=train_df['text'].values\n",
    "test_text=test_df['text'].values\n",
    "X=np.array([[int(top_word in text) for top_word in top_words] for text in train_text])\n",
    "y=train_df['target'].values\n",
    "test_X=np.array([[int(top_word in text) for top_word in top_words] for text in test_text])\n",
    "print(f\"X.shape:{X.shape},y.shape:{y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f054e112",
   "metadata": {
    "papermill": {
     "duration": 0.008344,
     "end_time": "2024-03-26T05:55:54.502821",
     "exception": false,
     "start_time": "2024-03-26T05:55:54.494477",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 这里是我自己手写的朴素贝叶斯算法."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1d2f073",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T05:55:54.518073Z",
     "iopub.status.busy": "2024-03-26T05:55:54.517661Z",
     "iopub.status.idle": "2024-03-26T05:55:54.538312Z",
     "shell.execute_reply": "2024-03-26T05:55:54.536982Z"
    },
    "papermill": {
     "duration": 0.031693,
     "end_time": "2024-03-26T05:55:54.541212",
     "exception": false,
     "start_time": "2024-03-26T05:55:54.509519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#朴素贝叶斯分类算法\n",
    "class NaiveBayesClassifier():\n",
    "    \n",
    "    def __init__(self,num_classes=2):\n",
    "        self.num_classes=num_classes#我们假设是二分类任务\n",
    "        self.Pa=np.ones(self.num_classes)/self.num_classes#初始化每个类别概率相等,后续需要考虑target的分布.\n",
    "        self.target=np.arange(self.num_classes)#分类的几种类别是什么\n",
    "        self.features=[]#X每列分别有哪些类别\n",
    "        self.featureP=[]#y=target[i]时X的j列为第K种类别的概率\n",
    "        self.eps=1e-15#防止被除数为0\n",
    "    def fit(self,train_X,train_y):\n",
    "        self.target=sorted(np.unique(train_y))#训练数据y中出现几种类别\n",
    "        self.num_classes=len(self.target)#类别数为多少\n",
    "        feature=train_X.T#第i行就是第i个特征\n",
    "        #统计每个特征有哪几种类别\n",
    "        for i in range(len(feature)):\n",
    "            self.features.append(np.unique(feature[i]))\n",
    "\n",
    "        #用来统计y为每个类别的概率\n",
    "        Pa=[]\n",
    "        for i in range(len(self.target)):\n",
    "            Pa.append(np.mean(train_y==self.target[i]))\n",
    "        self.Pa=Pa\n",
    "        \n",
    "        #统计y=target[i]时每个特征每个类别的概率\n",
    "        for i in range(len(self.target)):\n",
    "            #当y=target[i]的时候的训练数据\n",
    "            target_X=train_X[np.where((y==self.target[i]))[0]]\n",
    "            \n",
    "            #统计所有特征每个类别的概率\n",
    "            feature_X=target_X.T\n",
    "            featurePs=[]#y=target时X每种概率的分布情况\n",
    "            for j in range(len(feature_X)):#第j个feature有这几种类别:self.features[j]\n",
    "                \n",
    "                #统计train_X中第j个特征每个类别的概率\n",
    "                featureP=[]\n",
    "                for k in range(len(self.features[j])):\n",
    "                    featureP.append(np.mean(feature_X[j]==self.features[j][k]))\n",
    "                \n",
    "                featurePs.append(featureP)\n",
    "            self.featureP.append(featurePs)\n",
    "            \n",
    "    def predict_proba(self,test_X):\n",
    "        #每个数据每个类别的概率\n",
    "        test_pros=np.zeros((len(test_X),self.num_classes))\n",
    "        \n",
    "        for i in range(len(test_X)):#test_X[i]是其中一个数据\n",
    "            #数据text_X[i]统计每个类别的概率:P(X0[0]|y=y0)P(X0[1]|y=y0)……P(X0[n]|y=y0)P(y=y0)\n",
    "            test_pro=np.zeros((self.num_classes))\n",
    "            for j in range(self.num_classes):\n",
    "                init_p=self.Pa[j]#P(y=y0)\n",
    "                #找到text_X的第i个数据在y=target[j]时第k个特征的概率\n",
    "                for k in range(len(test_X[i])):\n",
    "                    Pba=self.Pa[j]\n",
    "                    #找到第test_X的第i个数据的第K个特征是什么?\n",
    "                    for l in range(len(self.features[k])):\n",
    "                        if test_X[i][k]==self.features[k][l]:\n",
    "                            Pba=self.featureP[j][k][l]      \n",
    "                    init_p*=Pba\n",
    "                test_pro[j]=init_p\n",
    "            test_pros[i]=test_pro\n",
    "        #最后对预测的概率进行归一化的操作\n",
    "        test_pros=test_pros/ (np.sum(test_pros,axis=1).reshape(-1,1)+self.eps)\n",
    "        return test_pros\n",
    " \n",
    "    def predict(self,test_X):\n",
    "        test_pros=self.predict_proba(test_X)\n",
    "        test_preds=np.argmax(test_pros,axis=1)\n",
    "        return test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498760cd",
   "metadata": {
    "papermill": {
     "duration": 0.006336,
     "end_time": "2024-03-26T05:55:54.554429",
     "exception": false,
     "start_time": "2024-03-26T05:55:54.548093",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 如果单看训练数据,准确率达到了0.81,其实在测试数据上还是有0.78的准确率."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ed17dbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T05:55:54.569822Z",
     "iopub.status.busy": "2024-03-26T05:55:54.569354Z",
     "iopub.status.idle": "2024-03-26T05:56:58.342574Z",
     "shell.execute_reply": "2024-03-26T05:56:58.341312Z"
    },
    "papermill": {
     "duration": 63.784601,
     "end_time": "2024-03-26T05:56:58.345623",
     "exception": false,
     "start_time": "2024-03-26T05:55:54.561022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.8122947589649284\n"
     ]
    }
   ],
   "source": [
    "def accuracy(y_true,y_pred):\n",
    "    return np.mean(y_true==y_pred)\n",
    "model=NaiveBayesClassifier()\n",
    "model.fit(X,y)\n",
    "y_pred=model.predict(X)\n",
    "print(f\"accuracy:{accuracy(y_pred,y)}\")\n",
    "test_pred=model.predict(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ca68a4",
   "metadata": {
    "papermill": {
     "duration": 0.006413,
     "end_time": "2024-03-26T05:56:58.359097",
     "exception": false,
     "start_time": "2024-03-26T05:56:58.352684",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 我们也可以看看python开源库的朴素贝叶斯分类器,效果比我的算法略好一点."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8e25b67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T05:56:58.377452Z",
     "iopub.status.busy": "2024-03-26T05:56:58.376637Z",
     "iopub.status.idle": "2024-03-26T05:56:58.944560Z",
     "shell.execute_reply": "2024-03-26T05:56:58.943219Z"
    },
    "papermill": {
     "duration": 0.580257,
     "end_time": "2024-03-26T05:56:58.947545",
     "exception": false,
     "start_time": "2024-03-26T05:56:58.367288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8128201760147117"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://www.kaggle.com/code/hadriencr/ml-olympiad-naivebayesclassifier\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "classifier = CategoricalNB()\n",
    "classifier.fit(X,y)\n",
    "accuracy(classifier.predict(X),y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aace80",
   "metadata": {
    "papermill": {
     "duration": 0.00673,
     "end_time": "2024-03-26T05:56:58.961494",
     "exception": false,
     "start_time": "2024-03-26T05:56:58.954764",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 这里就是把预测结果提交,看看成绩."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f897281b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T05:56:58.978297Z",
     "iopub.status.busy": "2024-03-26T05:56:58.977080Z",
     "iopub.status.idle": "2024-03-26T05:56:59.009467Z",
     "shell.execute_reply": "2024-03-26T05:56:59.008087Z"
    },
    "papermill": {
     "duration": 0.043767,
     "end_time": "2024-03-26T05:56:59.012435",
     "exception": false,
     "start_time": "2024-03-26T05:56:58.968668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       1\n",
       "1   2       0\n",
       "2   3       0\n",
       "3   9       0\n",
       "4  11       1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission=pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")\n",
    "submission['target']=test_pred\n",
    "submission.to_csv(\"submission.csv\",index=None)\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 869809,
     "sourceId": 17777,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 84.23559,
   "end_time": "2024-03-26T05:56:59.744079",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-26T05:55:35.508489",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
